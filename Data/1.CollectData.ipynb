{"cells":[{"cell_type":"markdown","id":"f1cd78e5","metadata":{"id":"f1cd78e5"},"source":["# 1.Import dependencies"]},{"cell_type":"code","execution_count":null,"id":"c7e6d554","metadata":{"id":"c7e6d554","outputId":"292a5ce0-0f46-45da-e1a0-2fa3bae28918"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: opencv-python in /home/hoangha/anaconda3/envs/CV-detection/lib/python3.6/site-packages (4.5.5.64)\r\n","Requirement already satisfied: numpy>=1.13.3 in /home/hoangha/anaconda3/envs/CV-detection/lib/python3.6/site-packages (from opencv-python) (1.19.5)\r\n"]}],"source":["!pip install opencv-python"]},{"cell_type":"code","execution_count":null,"id":"173e5bf8","metadata":{"id":"173e5bf8"},"outputs":[],"source":["import cv2\n","import uuid\n","import os\n","import time"]},{"cell_type":"markdown","id":"131a4f00","metadata":{"id":"131a4f00"},"source":["# 2.Define Images to Collect"]},{"cell_type":"code","execution_count":null,"id":"f00d2607","metadata":{"id":"f00d2607"},"outputs":[],"source":["labels = ['one', 'two', 'three', 'four', 'five']\n","number_imgs = 5"]},{"cell_type":"markdown","id":"888551fd","metadata":{"id":"888551fd"},"source":["# 3.Setup Folders"]},{"cell_type":"code","execution_count":null,"id":"18c67086","metadata":{"id":"18c67086"},"outputs":[],"source":["IMAGES_PATH = 'collectedimages'"]},{"cell_type":"code","execution_count":null,"id":"d3eedbcf","metadata":{"id":"d3eedbcf"},"outputs":[],"source":["if not os.path.exists(IMAGES_PATH):\n","    os.makedirs(IMAGES_PATH, exist_ok=True)\n","for label in labels:\n","    path = os.path.join(IMAGES_PATH, label)\n","    if not os.path.exists(path):\n","        os.mkdir(path)"]},{"cell_type":"markdown","id":"7f6dfab2","metadata":{"id":"7f6dfab2"},"source":["# 4.Capture Images"]},{"cell_type":"code","execution_count":null,"id":"8562e4d8","metadata":{"id":"8562e4d8","outputId":"43e91464-5333-4d34-b00e-076fe95e5bf7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collection images for two\n","Collecting image 0\n","Collecting image 1\n","Collecting image 2\n","Collecting image 3\n","Collecting image 4\n"]}],"source":["for label in labels:\n","    cap = cv2.VideoCapture(0)\n","    \n","    print(f'Collection images for {label}')\n","    time.sleep(2)\n","    for imgnum in range(number_imgs):\n","        print(f'Collecting image {imgnum}')\n","        time.sleep(5)\n","        ret, frame = cap.read()\n","        imgname = os.path.join(IMAGES_PATH, label, f'{label}_{uuid.uuid1()}.jpg')\n","        cv2.imwrite(imgname, frame)\n","        cv2.imshow('frame', frame)\n","        time.sleep(2)\n","        \n","        if cv2.waitKey(1) & 0xFF == ord('q'):\n","            break\n","    cap.release()\n","cv2.destroyAllWindows()"]},{"cell_type":"markdown","id":"ab73f032","metadata":{"id":"ab73f032"},"source":["# 5.Image Labelling"]},{"cell_type":"code","execution_count":null,"id":"f2c4a678","metadata":{"id":"f2c4a678"},"outputs":[],"source":["LABEL_PATH = 'labelimg'"]},{"cell_type":"code","execution_count":null,"id":"27d3232c","metadata":{"id":"27d3232c"},"outputs":[],"source":["if not os.path.exists(LABEL_PATH):\n","    os.makedirs(LABEL_PATH)"]},{"cell_type":"code","execution_count":null,"id":"6c0585fd","metadata":{"id":"6c0585fd","outputId":"eb694269-1f68-4cf1-b1aa-816efb13c751"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'Tensorflow/labelimg'...\n","remote: Enumerating objects: 1986, done.\u001b[K\n","remote: Total 1986 (delta 0), reused 0 (delta 0), pack-reused 1986\u001b[K\n","Receiving objects: 100% (1986/1986), 232.85 MiB | 1.28 MiB/s, done.\n","Resolving deltas: 100% (1186/1186), done.\n"]}],"source":["# if alreaddy cloned, comment the below command line\n","!git clone https://github.com/tzutalin/labelImg.git {LABEL_PATH}"]},{"cell_type":"code","execution_count":null,"id":"1f0b9412","metadata":{"id":"1f0b9412"},"outputs":[],"source":["# if already installed, comment the below command line\n","!pip install --upgrade pyqt5 lxml "]},{"cell_type":"code","execution_count":null,"id":"76c04cab","metadata":{"id":"76c04cab","outputId":"a81bde1e-4e4c-4c25-a533-cd0b883fd5ef"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: pyqt5 in /home/hoangha/anaconda3/envs/CV-detection/lib/python3.6/site-packages (5.15.6)\n","Requirement already satisfied: lxml in /home/hoangha/anaconda3/envs/CV-detection/lib/python3.6/site-packages (4.8.0)\n","Requirement already satisfied: PyQt5-Qt5>=5.15.2 in /home/hoangha/anaconda3/envs/CV-detection/lib/python3.6/site-packages (from pyqt5) (5.15.2)\n","Requirement already satisfied: PyQt5-sip<13,>=12.8 in /home/hoangha/anaconda3/envs/CV-detection/lib/python3.6/site-packages (from pyqt5) (12.9.1)\n","Collecting pyqt5==5.14.1\n","  Downloading PyQt5-5.14.1-5.14.1-cp35.cp36.cp37.cp38-abi3-manylinux2014_x86_64.whl (63.5 MB)\n","\u001b[K     |████████████████████████████████| 63.5 MB 13.3 MB/s eta 0:00:01   |█▌                              | 2.9 MB 3.4 MB/s eta 0:00:19     |████████████████▉               | 33.3 MB 2.0 MB/s eta 0:00:15\n","\u001b[?25hCollecting lxml==4.6.5\n","  Downloading lxml-4.6.5-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (6.3 MB)\n","\u001b[K     |████████████████████████████████| 6.3 MB 8.6 MB/s eta 0:00:01\n","\u001b[?25hRequirement already satisfied: PyQt5-sip<13,>=12.7 in /home/hoangha/anaconda3/envs/CV-detection/lib/python3.6/site-packages (from pyqt5==5.14.1->-r requirements/requirements-linux-python3.txt (line 1)) (12.9.1)\n","Installing collected packages: pyqt5, lxml\n","  Attempting uninstall: pyqt5\n","    Found existing installation: PyQt5 5.15.6\n","    Uninstalling PyQt5-5.15.6:\n","      Successfully uninstalled PyQt5-5.15.6\n","  Attempting uninstall: lxml\n","    Found existing installation: lxml 4.8.0\n","    Uninstalling lxml-4.8.0:\n","      Successfully uninstalled lxml-4.8.0\n","Successfully installed lxml-4.6.5 pyqt5-5.14.1\n","pyrcc5 -o libs/resources.py resources.qrc\n"]}],"source":["!cd {LABEL_PATH} && pip install -r requirements/requirements-linux-python3.txt\n","!cd {LABEL_PATH} && make qt5py3"]},{"cell_type":"code","execution_count":null,"id":"f50a84f4","metadata":{"id":"f50a84f4"},"outputs":[],"source":["with open(f'{LABEL_PATH}/data/predefined_classes.txt', 'w') as f:\n","    for label in labels:\n","        f.write(label+'\\n')"]},{"cell_type":"code","execution_count":null,"id":"0029cb2f","metadata":{"id":"0029cb2f","outputId":"e82fa2d3-ec74-4733-ba88-cdb977e1f273"},"outputs":[{"name":"stdout","output_type":"stream","text":["one\r\n","two\r\n","three\r\n","four\r\n","five\r\n"]}],"source":["!cat {LABEL_PATH}/data/predefined_classes.txt"]},{"cell_type":"code","execution_count":null,"id":"d56cc870","metadata":{"id":"d56cc870","outputId":"58816040-d9e7-4520-d0c2-e49c1447f4ff"},"outputs":[{"name":"stdout","output_type":"stream","text":["Loading setting failed\n","Image:/home/hoangha/Desktop/ComputerVision/TensorflowObjectDetection/Tensorflow/workspace/images/collectedimages/two/two_af36ee10-cbd9-11ec-8480-5172992c705b.jpg -> Annotation:/home/hoangha/Desktop/ComputerVision/TensorflowObjectDetection/Tensorflow/workspace/images/collectedimages/two/two_af36ee10-cbd9-11ec-8480-5172992c705b.xml\n","Image:/home/hoangha/Desktop/ComputerVision/TensorflowObjectDetection/Tensorflow/workspace/images/collectedimages/two/two_b53237a2-cbd9-11ec-8480-5172992c705b.jpg -> Annotation:/home/hoangha/Desktop/ComputerVision/TensorflowObjectDetection/Tensorflow/workspace/images/collectedimages/two/two_b53237a2-cbd9-11ec-8480-5172992c705b.xml\n","Image:/home/hoangha/Desktop/ComputerVision/TensorflowObjectDetection/Tensorflow/workspace/images/collectedimages/two/two_bb2b2b96-cbd9-11ec-8480-5172992c705b.jpg -> Annotation:/home/hoangha/Desktop/ComputerVision/TensorflowObjectDetection/Tensorflow/workspace/images/collectedimages/two/two_bb2b2b96-cbd9-11ec-8480-5172992c705b.xml\n","Image:/home/hoangha/Desktop/ComputerVision/TensorflowObjectDetection/Tensorflow/workspace/images/collectedimages/two/two_c71d3b7e-cbd9-11ec-8480-5172992c705b.jpg -> Annotation:/home/hoangha/Desktop/ComputerVision/TensorflowObjectDetection/Tensorflow/workspace/images/collectedimages/two/two_c71d3b7e-cbd9-11ec-8480-5172992c705b.xml\n","Image:/home/hoangha/Desktop/ComputerVision/TensorflowObjectDetection/Tensorflow/workspace/images/collectedimages/two/two_c123e2d6-cbd9-11ec-8480-5172992c705b.jpg -> Annotation:/home/hoangha/Desktop/ComputerVision/TensorflowObjectDetection/Tensorflow/workspace/images/collectedimages/two/two_c123e2d6-cbd9-11ec-8480-5172992c705b.xml\n","Image:/home/hoangha/Desktop/ComputerVision/TensorflowObjectDetection/Tensorflow/workspace/images/collectedimages/two/two_d0ae8918-cbd9-11ec-8480-5172992c705b.jpg -> Annotation:/home/hoangha/Desktop/ComputerVision/TensorflowObjectDetection/Tensorflow/workspace/images/collectedimages/two/two_d0ae8918-cbd9-11ec-8480-5172992c705b.xml\n","Image:/home/hoangha/Desktop/ComputerVision/TensorflowObjectDetection/Tensorflow/workspace/images/collectedimages/two/two_d6a8edcc-cbd9-11ec-8480-5172992c705b.jpg -> Annotation:/home/hoangha/Desktop/ComputerVision/TensorflowObjectDetection/Tensorflow/workspace/images/collectedimages/two/two_d6a8edcc-cbd9-11ec-8480-5172992c705b.xml\n","Image:/home/hoangha/Desktop/ComputerVision/TensorflowObjectDetection/Tensorflow/workspace/images/collectedimages/two/two_dca30e60-cbd9-11ec-8480-5172992c705b.jpg -> Annotation:/home/hoangha/Desktop/ComputerVision/TensorflowObjectDetection/Tensorflow/workspace/images/collectedimages/two/two_dca30e60-cbd9-11ec-8480-5172992c705b.xml\n","Image:/home/hoangha/Desktop/ComputerVision/TensorflowObjectDetection/Tensorflow/workspace/images/collectedimages/two/two_e3b741be-cbd7-11ec-8480-5172992c705b.jpg -> Annotation:/home/hoangha/Desktop/ComputerVision/TensorflowObjectDetection/Tensorflow/workspace/images/collectedimages/two/two_e3b741be-cbd7-11ec-8480-5172992c705b.xml\n","Image:/home/hoangha/Desktop/ComputerVision/TensorflowObjectDetection/Tensorflow/workspace/images/collectedimages/two/two_e4eae3e2-cbd7-11ec-8480-5172992c705b.jpg -> Annotation:/home/hoangha/Desktop/ComputerVision/TensorflowObjectDetection/Tensorflow/workspace/images/collectedimages/two/two_e4eae3e2-cbd7-11ec-8480-5172992c705b.xml\n","Image:/home/hoangha/Desktop/ComputerVision/TensorflowObjectDetection/Tensorflow/workspace/images/collectedimages/two/two_e29bf78c-cbd9-11ec-8480-5172992c705b.jpg -> Annotation:/home/hoangha/Desktop/ComputerVision/TensorflowObjectDetection/Tensorflow/workspace/images/collectedimages/two/two_e29bf78c-cbd9-11ec-8480-5172992c705b.xml\n","Image:/home/hoangha/Desktop/ComputerVision/TensorflowObjectDetection/Tensorflow/workspace/images/collectedimages/two/two_e753e87c-cbd7-11ec-8480-5172992c705b.jpg -> Annotation:/home/hoangha/Desktop/ComputerVision/TensorflowObjectDetection/Tensorflow/workspace/images/collectedimages/two/two_e753e87c-cbd7-11ec-8480-5172992c705b.xml\n","Image:/home/hoangha/Desktop/ComputerVision/TensorflowObjectDetection/Tensorflow/workspace/images/collectedimages/two/two_e62034ba-cbd7-11ec-8480-5172992c705b.jpg -> Annotation:/home/hoangha/Desktop/ComputerVision/TensorflowObjectDetection/Tensorflow/workspace/images/collectedimages/two/two_e62034ba-cbd7-11ec-8480-5172992c705b.xml\n","Image:/home/hoangha/Desktop/ComputerVision/TensorflowObjectDetection/Tensorflow/workspace/images/collectedimages/two/two_e8875404-cbd7-11ec-8480-5172992c705b.jpg -> Annotation:/home/hoangha/Desktop/ComputerVision/TensorflowObjectDetection/Tensorflow/workspace/images/collectedimages/two/two_e8875404-cbd7-11ec-8480-5172992c705b.xml\n","Image:/home/hoangha/Desktop/ComputerVision/TensorflowObjectDetection/Tensorflow/workspace/images/collectedimages/two/two_e8945148-cbd9-11ec-8480-5172992c705b.jpg -> Annotation:/home/hoangha/Desktop/ComputerVision/TensorflowObjectDetection/Tensorflow/workspace/images/collectedimages/two/two_e8945148-cbd9-11ec-8480-5172992c705b.xml\n","Image:/home/hoangha/Desktop/ComputerVision/TensorflowObjectDetection/Tensorflow/workspace/images/collectedimages/two/two_eaefcb9a-cbd7-11ec-8480-5172992c705b.jpg -> Annotation:/home/hoangha/Desktop/ComputerVision/TensorflowObjectDetection/Tensorflow/workspace/images/collectedimages/two/two_eaefcb9a-cbd7-11ec-8480-5172992c705b.xml\n","Image:/home/hoangha/Desktop/ComputerVision/TensorflowObjectDetection/Tensorflow/workspace/images/collectedimages/two/two_ec238240-cbd7-11ec-8480-5172992c705b.jpg -> Annotation:/home/hoangha/Desktop/ComputerVision/TensorflowObjectDetection/Tensorflow/workspace/images/collectedimages/two/two_ec238240-cbd7-11ec-8480-5172992c705b.xml\n","Image:/home/hoangha/Desktop/ComputerVision/TensorflowObjectDetection/Tensorflow/workspace/images/collectedimages/two/two_ee8ac6a6-cbd7-11ec-8480-5172992c705b.jpg -> Annotation:/home/hoangha/Desktop/ComputerVision/TensorflowObjectDetection/Tensorflow/workspace/images/collectedimages/two/two_ee8ac6a6-cbd7-11ec-8480-5172992c705b.xml\n"]}],"source":["!cd {LABEL_PATH} && python labelImg.py "]},{"cell_type":"code","execution_count":null,"id":"b39df300","metadata":{"id":"b39df300"},"outputs":[],"source":[""]}],"metadata":{"kernelspec":{"display_name":"Python [conda env:CV-detection]","language":"python","name":"conda-env-CV-detection-py"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.13"},"colab":{"name":"1.CollectData.ipynb","provenance":[],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":5}